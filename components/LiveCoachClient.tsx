"use client";

import React, { useState, useEffect, useRef } from 'react';
import { GoogleGenAI } from '@google/genai';
import { Mic, MicOff, PhoneOff, PhoneCall, Activity, Volume2, Sparkles, BookOpen, Coffee, Stethoscope, Briefcase, HelpCircle, X, MessageSquare } from 'lucide-react';
import AudioVisualizer from './AudioVisualizer'; // Import

// --- Constants & Types ---

const MODEL_NAME = "gemini-2.5-flash-native-audio-preview-12-2025";

interface LiveCoachProps {
    language: string;
    targetLanguageName?: string;
    userNativeLanguageName?: string;
    initialMessage?: string;
    apiKey: string | null;
    customSystemInstruction?: string;
    hideRoleSelector?: boolean;
    onTranscriptUpdate?: (transcript: Transcript) => void;
}

export interface Transcript {
    role: 'user' | 'model';
    text: string;
}

interface Correction {
    original: string;
    correction: string;
    explanation: string;
}

// Localized Roles Helper
const getRoles = (lang: string) => {
    // Default to defaults if language not found, but we will provide main ones.
    // Note: We keep the IDs stable.

    const descriptions: Record<string, any> = {
        'ES': {
            tutor: 'Eres Mar√≠a, una tutora de idiomas entusiasta y paciente. Tu objetivo es aumentar la confianza del estudiante. Habla con claridad y un poco m√°s despacio de lo normal. Corrige los errores importantes reformulando suavemente, pero no interrumpas el flujo. Haz preguntas abiertas sobre su vida para fomentar el habla. S√© solidaria y usa un tono c√°lido.',
            barista: 'Eres Diego, el barista m√°s genial de "Caf√© Sol". El ambiente es en√©rgico, con sonidos de cafetera de fondo. Eres hablador, encantador y usas jerga casual apropiada para una cafeter√≠a. Quieres saber los detalles de su pedido, pero tambi√©n c√≥mo va su d√≠a. Mant√©n la charla √°gil y urbana.',
            doctor: 'Eres la Dra. Elena, una m√©dica altamente competente y emp√°tica. Est√°s realizando un triaje. Tu tono es tranquilo, tranquilizador, pero enfocado. Usa terminolog√≠a m√©dica precisa al explicar, pero haz preguntas simples. Pasos: 1. S√≠ntomas, 2. Duraci√≥n, 3. Nivel de dolor, 4. Diagn√≥stico/Consejo. Haz que el usuario se sienta cuidado.',
            interviewer: 'Eres Marcus Sterling, gerente de adquisici√≥n de talento en una empresa tecnol√≥gica l√≠der. Eres profesional, agudo y orientado a resultados. Est√°s evaluando las "Habilidades Blandas" y el "Ajuste Cultural" del candidato. Haz preguntas de comportamiento ("Cu√©ntame sobre una vez que..."). Desaf√≠a sus respuestas ligeramente para ver c√≥mo reaccionan bajo presi√≥n, pero mant√©n la profesionalidad.'
        },
        'FR': {
            tutor: 'Vous √™tes Maria, une tutrice de langues enthousiaste et patiente. Votre objectif est de renforcer la confiance de l\'√©tudiant. Parlez clairement et un peu plus lentement que la normale. Corrigez les erreurs importantes en reformulant doucement, mais n\'interrompez pas le flux. Posez des questions ouvertes sur leur vie pour encourager la parole. Soyez encourageante et chaleureuse.',
            barista: 'Vous √™tes Diego, le barista le plus cool du "Caf√© Sol". L\'ambiance est √©nergique. Vous √™tes bavard, charmant et utilisez un argot d√©contract√© appropri√© pour un caf√©. Vous voulez conna√Ætre les d√©tails de leur commande, mais aussi comment se passe leur journ√©e. Gardez la conversation vive et urbaine.',
            doctor: 'Vous √™tes le Dr Elena, un m√©decin tr√®s comp√©tent et empathique. Vous effectuez un triage. Votre ton est calme, rassurant mais concentr√©. Utilisez une terminologie m√©dicale pr√©cise lors des explications, mais posez des questions simples. √âtapes : 1. Sympt√¥mes, 2. Dur√©e, 3. Niveau de douleur, 4. Diagnostic/Conseil. Faites sentir √† l\'utilisateur qu\'il est pris en charge.',
            interviewer: 'Vous √™tes Marcus Sterling, responsable du recrutement dans une grande entreprise tech. Vous √™tes professionnel, perspicace et ax√© sur les r√©sultats. Vous √©valuez les "Soft Skills" et le "Fit Culturel". Posez des questions comportementales ("Parlez-moi d\'une fois o√π..."). Challengez l√©g√®rement leurs r√©ponses pour voir leur r√©action sous pression, mais restez professionnel.'
        },
        'DE': {
            tutor: 'Du bist Maria, eine enthusiastische und geduldige Sprachtutorin. Dein Ziel ist es, das Selbstvertrauen des Sch√ºlers zu st√§rken. Sprich deutlich und etwas langsamer als normal. Korrigiere wichtige Fehler durch sanftes Umformulieren, aber unterbrich nicht den Fluss. Stelle offene Fragen √ºber ihr Leben. Sei unterst√ºtzend und warmherzig.',
            barista: 'Du bist Diego, der coolste Barista im "Caf√© Sol". Die Atmosph√§re ist energiegeladen. Du bist gespr√§chig, charmant und verwendest lockere Umgangssprache. Du willst die Details ihrer Bestellung wissen, aber auch, wie ihr Tag l√§uft. Halte das Gespr√§ch flott und urban.',
            doctor: 'Du bist Dr. Elena, eine kompetente und einf√ºhlsame √Ñrztin. Du f√ºhrst eine Triage durch. Dein Ton ist ruhig, beruhigend, aber fokussiert. Verwende pr√§zise medizinische Fachbegriffe beim Erkl√§ren, aber stelle einfache Fragen. Schritte: 1. Symptome, 2. Dauer, 3. Schmerzlevel, 4. Diagnose/Rat. Gib dem Benutzer das Gef√ºhl, gut aufgehoben zu sein.',
            interviewer: 'Du bist Marcus Sterling, Talent Acquisition Manager bei einer Top-Tech-Firma. Du bist professionell, scharfsinnig und ergebnisorientiert. Du bewertest "Soft Skills" und "Cultural Fit". Stelle Verhaltensfragen ("Erz√§hl mir von einem Mal, als..."). Fordere ihre Antworten leicht heraus, um ihre Reaktion unter Druck zu sehen, bleibe aber professionell.'
        },
        'IT': {
            tutor: 'Sei Maria, una tutor di lingue entusiasta e paziente. Il tuo obiettivo √® aumentare la fiducia dello studente. Parla chiaramente e un po\' pi√π lentamente del normale. Correggi gli errori importanti riformulando gentilmente, ma non interrompi il flusso. Fai domande aperte sulla loro vita. Sii solidale e usa un tono caldo.',
            barista: 'Sei Diego, il barista pi√π cool del "Caf√© Sol". L\'atmosfera √® energica. Sei loquace, affascinante e usi uno slang informale appropriato per un caff√®. Vuoi sapere i dettagli del loro ordine, ma anche come va la loro giornata. Mantieni la conversazione vivace e urbana.',
            doctor: 'Sei la Dott.ssa Elena, un medico altamente competente ed empatico. Stai effettuando un triage. Il tuo tono √® calmo, rassicurante ma concentrato. Usa terminologia medica precisa quando spieghi, ma fai domande semplici. Passaggi: 1. Sintomi, 2. Durata, 3. Livello di dolore, 4. Diagnosi/Consiglio. Fai sentire l\'utente accudito.',
            interviewer: 'Sei Marcus Sterling, responsabile acquisizione talenti in una top tech firm. Sei professionale, acuto e orientato ai risultati. Stai valutando le "Soft Skills" e il "Cultural Fit". Fai domande comportamentali ("Raccontami di una volta che..."). Sfida leggermente le loro risposte per vedere come reagiscono sotto pressione, ma rimani professionale.'
        },
        'PT': {
            tutor: 'Voc√™ √© Maria, uma tutora de idiomas entusiasmada e paciente. Seu objetivo √© aumentar a confian√ßa do aluno. Fale com clareza e um pouco mais devagar que o normal. Corrija erros importantes reformulando gentilmente, mas n√£o interrompa o fluxo. Fa√ßa perguntas abertas sobre a vida deles. Seja solid√°ria e use um tom caloroso.',
            barista: 'Voc√™ √© Diego, o barista mais legal do "Caf√© Sol". A atmosfera √© energ√©tica. Voc√™ √© falante, charmoso e usa g√≠rias casuais apropriadas para um caf√©. Voc√™ quer saber os detalhes do pedido, mas tamb√©m como est√° o dia deles. Mantenha a conversa viva e urbana.',
            doctor: 'Voc√™ √© a Dra. Elena, uma m√©dica altamente competente e emp√°tica. Voc√™ est√° fazendo uma triagem. Seu tom √© calmo, tranquilizador, mas focado. Use terminologia m√©dica precisa ao explicar, mas fa√ßa perguntas simples. Passos: 1. Sintomas, 2. Dura√ß√£o, 3. N√≠vel de dor, 4. Diagn√≥stico/Conselho. Fa√ßa o usu√°rio se sentir cuidado.',
            interviewer: 'Voc√™ √© Marcus Sterling, gerente de aquisi√ß√£o de talentos em uma grande empresa de tecnologia. Voc√™ √© profissional, perspicaz e orientado a resultados. Voc√™ est√° avaliando "Soft Skills" e "Cultural Fit". Fa√ßa perguntas comportamentais ("Conte-me sobre uma vez que..."). Desafie levemente as respostas para ver a rea√ß√£o sob press√£o, mas mantenha o profissionalismo.'
        },
        'JP': {
            tutor: '„ÅÇ„Å™„Åü„ÅØ„Éû„É™„Ç¢„ÄÅÁÜ±ÂøÉ„ÅßÂøçËÄêÂº∑„ÅÑË™ûÂ≠¶ÊïôÂ∏´„Åß„Åô„ÄÇÁõÆÊ®ô„ÅØÁîüÂæí„ÅÆËá™‰ø°„ÇíÈ´ò„ÇÅ„Çã„Åì„Å®„Åß„Åô„ÄÇÊôÆÊÆµ„Çà„ÇäÂ∞ë„Åó„ÇÜ„Å£„Åè„Çä„ÄÅ„ÅØ„Å£„Åç„Çä„Å®Ë©±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÈáçË¶Å„Å™ÈñìÈÅï„ÅÑ„ÅØÂÑ™„Åó„ÅèË®Ä„ÅÑÁõ¥„Åó„Å¶Ë®ÇÊ≠£„Åó„Åæ„Åô„Åå„ÄÅ‰ºöË©±„ÅÆÊµÅ„Çå„ÇíÊ≠¢„ÇÅ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇÁîüÂæí„ÅÆÁîüÊ¥ª„Å´„Å§„ÅÑ„Å¶Ëá™Áî±„Å™Ë≥™Âïè„Çí„Åó„Å¶„ÄÅÁô∫Ë©±„Çí‰øÉ„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇÂçîÂäõÁöÑ„ÅßÊ∏©„Åã„ÅÑÂè£Ë™ø„Åß„ÄÇ',
            barista: '„ÅÇ„Å™„Åü„ÅØ„Äå„Ç´„Éï„Çß„Éª„ÇΩ„É´„Äç„Åß‰∏ÄÁï™„ÇØ„Éº„É´„Å™„Éê„É™„Çπ„Çø„ÄÅ„Éá„Ç£„Ç®„Ç¥„Åß„Åô„ÄÇÂ∫ó„ÅØÊ¥ªÊ∞ó„Å´Ê∫Ä„Å°„Å¶„ÅÑ„Åæ„Åô„ÄÇ„ÅÇ„Å™„Åü„ÅØË©±„ÅóÂ•Ω„Åç„ÅßÈ≠ÖÂäõÁöÑ„ÄÅ„Ç´„Éï„Çß„Å´„Åµ„Åï„Çè„Åó„ÅÑ„Ç´„Ç∏„É•„Ç¢„É´„Å™Ë®ÄËëâÈÅ£„ÅÑ„Çí„Åó„Åæ„Åô„ÄÇÊ≥®Êñá„ÅÆË©≥Á¥∞„Å†„Åë„Åß„Å™„Åè„ÄÅÂÆ¢„ÅÆ1Êó•„Åå„Å©„ÅÜ„Åã„ÇÇËÅû„Åç„Åü„ÅÑ„Å®ÊÄù„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ‰ºöË©±„ÇíÁîü„ÅçÁîü„Åç„Å®„ÄÅÈÉΩ‰ºöÁöÑ„Å´‰øù„Å°„Åæ„Åó„Çá„ÅÜ„ÄÇ',
            doctor: '„ÅÇ„Å™„Åü„ÅØ„Ç®„É¨„ÉäÂåªÂ∏´„ÄÅÈùûÂ∏∏„Å´ÊúâËÉΩ„ÅßÂÖ±ÊÑüÂäõ„ÅÆ„ÅÇ„ÇãÂåªÂ∏´„Åß„Åô„ÄÇ„Éà„É™„Ç¢„Éº„Ç∏„ÇíË°å„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂè£Ë™ø„ÅØÁ©è„ÇÑ„Åã„ÅßÂÆâÂøÉÊÑü„Çí‰∏é„Åà„Åæ„Åô„Åå„ÄÅÈõÜ‰∏≠„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇË™¨ÊòéÊôÇ„ÅØÊ≠£Á¢∫„Å™ÂåªÂ≠¶Áî®Ë™û„Çí‰Ωø„ÅÑ„Åæ„Åô„Åå„ÄÅË≥™Âïè„ÅØÁ∞°Âçò„Å´„ÄÇÊâãÈ†ÜÔºö1.ÁóáÁä∂„ÄÅ2.ÊúüÈñì„ÄÅ3.Áóõ„Åø„ÅÆ„É¨„Éô„É´„ÄÅ4.Ë®∫Êñ≠/„Ç¢„Éâ„Éê„Ç§„Çπ„ÄÇ„É¶„Éº„Ç∂„Éº„Å´Â§ßÂàá„Å´„Åï„Çå„Å¶„ÅÑ„Çã„Å®ÊÑü„Åò„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ',
            interviewer: '„ÅÇ„Å™„Åü„ÅØ„Éû„Éº„Ç´„Çπ„Éª„Çπ„Çø„Éº„É™„É≥„Ç∞„ÄÅÂ§ßÊâã„ÉÜ„ÉÉ„ÇØ‰ºÅÊ•≠„ÅÆ‰∫∫ÊùêÁç≤Âæó„Éû„Éç„Éº„Ç∏„É£„Éº„Åß„Åô„ÄÇ„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„ÅßÈã≠„Åè„ÄÅÁµêÊûúÈáçË¶ñ„Åß„Åô„ÄÇ„Äå„ÇΩ„Éï„Éà„Çπ„Ç≠„É´„Äç„Å®„Äå„Ç´„É´„ÉÅ„É£„Éº„Éï„Ç£„ÉÉ„Éà„Äç„ÇíË©ï‰æ°„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇË°åÂãïÈù¢Êé•„ÅÆË≥™ÂïèÔºà„Äå„Äú„Åó„ÅüÊôÇ„ÅÆ„Åì„Å®„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄçÔºâ„Çí„Åó„Åæ„Åô„ÄÇ„Éó„É¨„ÉÉ„Ç∑„É£„Éº„Å∏„ÅÆÂèçÂøú„ÇíË¶ã„Çã„Åü„ÇÅ„Å´Â∞ë„ÅóÁ≠î„Åà„Å´Áï∞Ë≠∞„ÇíÂî±„Åà„Åæ„Åô„Åå„ÄÅ„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Åï„Çí‰øù„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ'
        },
        'CN': {
            tutor: '‰Ω†ÊòØ MariaÔºå‰∏Ä‰ΩçÁÉ≠ÊÉÖËÄêÂøÉÁöÑËØ≠Ë®ÄÂØºÂ∏à„ÄÇ‰Ω†ÁöÑÁõÆÊ†áÊòØÂ¢ûÂº∫Â≠¶ÁîüÁöÑËá™‰ø°ÂøÉ„ÄÇËØ¥ËØùË¶ÅÊ∏ÖÊô∞ÔºåÊØîÂπ≥Êó∂Á®çÊÖ¢„ÄÇÈÄöËøáÊ∏©ÂíåÁöÑÈáçËø∞Á∫†Ê≠£ÈáçË¶ÅÈîôËØØÔºå‰ΩÜ‰∏çË¶ÅÊâìÊñ≠ÂØπËØùÊµÅ„ÄÇËØ¢ÈóÆÂÖ≥‰∫é‰ªñ‰ª¨ÁîüÊ¥ªÁöÑÂºÄÊîæÂºèÈóÆÈ¢ò‰ª•ÈºìÂä±ÂºÄÂè£„ÄÇÊÄÅÂ∫¶Ë¶ÅÊîØÊåÅÂíåÊ∏©Êöñ„ÄÇ',
            barista: '‰Ω†ÊòØ DiegoÔºå‚ÄúÈò≥ÂÖâÂíñÂï°È¶Ü‚ÄùÊúÄÈÖ∑ÁöÑÂíñÂï°Â∏à„ÄÇÊ∞îÊ∞õÂÖÖÊª°Ê¥ªÂäõ„ÄÇ‰Ω†ÂÅ•Ë∞à„ÄÅËø∑‰∫∫Ôºå‰ΩøÁî®ÈÄÇÂêàÂíñÂï°È¶ÜÁöÑ‰ºëÈó≤‰øöËØ≠„ÄÇ‰Ω†ÊÉ≥Áü•ÈÅìËÆ¢ÂçïÁªÜËäÇÔºå‰πüÊÉ≥Áü•ÈÅì‰ªñ‰ª¨Ëøô‰∏ÄÂ§©ËøáÂæóÂ¶Ç‰Ωï„ÄÇ‰øùÊåÅÂØπËØùÁîüÂä®ÂíåÈÉΩÂ∏ÇÊÑü„ÄÇ',
            doctor: '‰Ω†ÊòØ Elena ÂåªÁîüÔºå‰∏Ä‰ΩçËÉΩÂäõÊûÅÂº∫‰∏îÂØåÊúâÂêåÊÉÖÂøÉÁöÑÂåªÁîü„ÄÇ‰Ω†Ê≠£Âú®ËøõË°åÂàÜËØä„ÄÇËØ≠Ê∞îÂÜ∑Èùô„ÄÅ‰ª§‰∫∫ÂÆâÂøÉ‰ΩÜ‰∏ìÊ≥®„ÄÇËß£ÈáäÊó∂‰ΩøÁî®Á≤æÁ°ÆÁöÑÂåªÂ≠¶ÊúØËØ≠Ôºå‰ΩÜÊèêÈóÆË¶ÅÁÆÄÂçï„ÄÇÊ≠•È™§Ôºö1.ÁóáÁä∂Ôºå2.ÊåÅÁª≠Êó∂Èó¥Ôºå3.ÁñºÁóõÁ≠âÁ∫ßÔºå4.ËØäÊñ≠/Âª∫ËÆÆ„ÄÇËÆ©Áî®Êà∑ÊÑüÂà∞Ë¢´ÂÖ≥ÊÄÄ„ÄÇ',
            interviewer: '‰Ω†ÊòØ Marcus SterlingÔºå‰∏ÄÂÆ∂È°∂Â∞ñÁßëÊäÄÂÖ¨Âè∏ÁöÑ‰∫∫ÊâçÊãõËÅòÁªèÁêÜ„ÄÇ‰Ω†‰∏ì‰∏ö„ÄÅÊïèÈîê‰∏îÊ≥®ÈáçÁªìÊûú„ÄÇ‰Ω†Ê≠£Âú®ËØÑ‰º∞‚ÄúËΩØÊäÄËÉΩ‚ÄùÂíå‚ÄúÊñáÂåñÂ•ëÂêàÂ∫¶‚Äù„ÄÇÊèêÂá∫Ë°å‰∏∫Èù¢ËØïÈóÆÈ¢òÔºà‚ÄúÂëäËØâÊàë‰∏ÄÊ¨°‰Ω†‚Ä¶‚Ä¶‚ÄùÔºâ„ÄÇÁ®çÂæÆÊåëÊàò‰ªñ‰ª¨ÁöÑÂõûÁ≠î‰ª•ËßÇÂØüÂéãÂäõ‰∏ãÁöÑÂèçÂ∫îÔºå‰ΩÜ‰øùÊåÅ‰∏ì‰∏ö„ÄÇ'
        },
        'RU': {
            tutor: '–í—ã –ú–∞—Ä–∏—è, –ø–æ–ª–Ω—ã–π —ç–Ω—Ç—É–∑–∏–∞–∑–º–∞ –∏ —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–π —è–∑—ã–∫–æ–≤–æ–π —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä. –í–∞—à–∞ —Ü–µ–ª—å - –ø–æ–≤—ã—Å–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —É—á–µ–Ω–∏–∫–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ –Ω–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—ã—á–Ω–æ–≥–æ. –ò—Å–ø—Ä–∞–≤–ª—è–π—Ç–µ –≤–∞–∂–Ω—ã–µ –æ—à–∏–±–∫–∏, –º—è–≥–∫–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É—è, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–π—Ç–µ –ø–æ—Ç–æ–∫ —Ä–µ—á–∏. –ó–∞–¥–∞–≤–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ–± –∏—Ö –∂–∏–∑–Ω–∏. –ë—É–¥—å—Ç–µ –æ—Ç–∑—ã–≤—á–∏–≤—ã –∏ –≥–æ–≤–æ—Ä–∏—Ç–µ —Ç–µ–ø–ª—ã–º —Ç–æ–Ω–æ–º.',
            barista: '–í—ã –î–∏–µ–≥–æ, —Å–∞–º—ã–π –∫—Ä—É—Ç–æ–π –±–∞—Ä–∏—Å—Ç–∞ –≤ "Caf√© Sol". –ê—Ç–º–æ—Å—Ñ–µ—Ä–∞ —ç–Ω–µ—Ä–≥–∏—á–Ω–∞—è. –í—ã —Ä–∞–∑–≥–æ–≤–æ—Ä—á–∏–≤—ã, –æ–±–∞—è—Ç–µ–ª—å–Ω—ã –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –Ω–µ–ø—Ä–∏–Ω—É–∂–¥–µ–Ω–Ω—ã–π —Å–ª–µ–Ω–≥, —É–º–µ—Å—Ç–Ω—ã–π –≤ –∫–∞—Ñ–µ. –í—ã —Ö–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –∑–∞–∫–∞–∑–∞, –∞ —Ç–∞–∫–∂–µ –∫–∞–∫ –ø—Ä–æ—à–µ–ª –∏—Ö –¥–µ–Ω—å. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –∂–∏–≤–æ–π –∏ –≥–æ—Ä–æ–¥—Å–∫–æ–π —Ä–∏—Ç–º –±–µ—Å–µ–¥—ã.',
            doctor: '–í—ã –¥–æ–∫—Ç–æ—Ä –ï–ª–µ–Ω–∞, –≤—ã—Å–æ–∫–æ–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω—ã–π –∏ —á—É—Ç–∫–∏–π –≤—Ä–∞—á. –í—ã –ø—Ä–æ–≤–æ–¥–∏—Ç–µ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä (—Ç—Ä–∏–∞–∂). –í–∞—à —Ç–æ–Ω —Å–ø–æ–∫–æ–µ–Ω, –æ–±–Ω–∞–¥–µ–∂–∏–≤–∞–µ—Ç, –Ω–æ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—á–Ω—É—é –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –ø—Ä–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏, –Ω–æ –∑–∞–¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã. –®–∞–≥–∏: 1. –°–∏–º–ø—Ç–æ–º—ã, 2. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, 3. –£—Ä–æ–≤–µ–Ω—å –±–æ–ª–∏, 4. –î–∏–∞–≥–Ω–æ–∑/–°–æ–≤–µ—Ç. –ü—É—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á—É–≤—Å—Ç–≤—É–µ—Ç –∑–∞–±–æ—Ç—É.',
            interviewer: '–í—ã –ú–∞—Ä–∫—É—Å –°—Ç–µ—Ä–ª–∏–Ω–≥, –º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø–æ–¥–±–æ—Ä—É —Ç–∞–ª–∞–Ω—Ç–æ–≤ –≤ –≤–µ–¥—É—â–µ–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∫–æ–º–ø–∞–Ω–∏–∏. –í—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã, –ø—Ä–æ–Ω–∏—Ü–∞—Ç–µ–ª—å–Ω—ã –∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –í—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ "Soft Skills" –∏ "Cultural Fit". –ó–∞–¥–∞–≤–∞–π—Ç–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã ("–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –º–Ω–µ –æ —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞..."). –°–ª–µ–≥–∫–∞ –æ—Å–ø–∞—Ä–∏–≤–∞–π—Ç–µ –∏—Ö –æ—Ç–≤–µ—Ç—ã, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∞–∫—Ü–∏—é –ø–æ–¥ –¥–∞–≤–ª–µ–Ω–∏–µ–º, –Ω–æ –æ—Å—Ç–∞–≤–∞–π—Ç–µ—Å—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–º.'
        }
    };

    // Alias handling for JP/CN
    const rKey = lang === 'JP' ? 'JP' : lang === 'CN' ? 'CN' : (descriptions[lang] ? lang : 'ES');
    const desc = descriptions[rKey];

    // Fallback if desc is missing (should cover main langs)
    const t = (id: string) => desc?.[id] || descriptions['ES'][id] || "";

    return [
        {
            id: 'tutor',
            label: 'Tutor',
            icon: BookOpen,
            prompt: t('tutor'),
            voiceName: 'Aoede'
        },
        {
            id: 'barista',
            label: 'Barista',
            icon: Coffee,
            prompt: t('barista'),
            voiceName: 'Fenrir'
        },
        {
            id: 'doctor',
            label: 'Doctor',
            icon: Stethoscope,
            prompt: t('doctor'),
            voiceName: 'Kore'
        },
        {
            id: 'interviewer',
            label: 'Recruiter',
            icon: Briefcase,
            prompt: t('interviewer'),
            voiceName: 'Charon'
        },
    ];
}

export default function LiveCoachClient({ language, targetLanguageName, userNativeLanguageName, initialMessage, apiKey, customSystemInstruction, hideRoleSelector, onTranscriptUpdate }: LiveCoachProps) {
    // Dynamic Roles based on Language
    const roles = getRoles(language);

    const [isConnected, setIsConnected] = useState(false);
    const [isMuted, setIsMuted] = useState(false);
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [error, setError] = useState<string | null>(null);
    const [status, setStatus] = useState("Ready to call");
    const [transcripts, setTranscripts] = useState<Transcript[]>([]);
    const [audioVolume, setAudioVolume] = useState(0);
    const [currentRole, setCurrentRole] = useState(roles[0]); // Start with Tutor
    const [correction, setCorrection] = useState<Correction | null>(null);
    const [selectedWord, setSelectedWord] = useState<{ word: string, translation: string } | null>(null);

    // PTT State
    const [isPttMode, setIsPttMode] = useState(false); // Default to Auto (VAD)
    const [isPttActive, setIsPttActive] = useState(false);

    // Refs
    const wsSessionRef = useRef<any>(null);
    const audioContextRef = useRef<AudioContext | null>(null);
    const mediaStreamRef = useRef<MediaStream | null>(null);
    const processorRef = useRef<AudioWorkletNode | null>(null);
    const audioQueueRef = useRef<ArrayBuffer[]>([]);
    const audioBufferRef = useRef<Uint8Array | null>(null); // Buffer for small chunks
    const isPlayingRef = useRef(false);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const animationFrameRef = useRef<number | null>(null);
    const isMutedRef = useRef(isMuted);
    const currentSourceRef = useRef<AudioBufferSourceNode | null>(null);
    const nextStartTimeRef = useRef<number>(0);
    const playbackTimeoutRef = useRef<NodeJS.Timeout | null>(null);

    // PTT Refs
    const isPttModeRef = useRef(false);
    const isPttActiveRef = useRef(false);

    // Watchdog Refs (Fix for "AI stops listening after silence")
    const lastAudioSentAtRef = useRef<number>(0);
    const audioStreamEndedRef = useRef<boolean>(false);
    const silenceIntervalRef = useRef<number | null>(null);
    const isSpeakingRef = useRef<boolean>(false); // Track if user is currently speaking

    // Sync Refs
    useEffect(() => {
        isMutedRef.current = isMuted;
        if (mediaStreamRef.current) {
            mediaStreamRef.current.getAudioTracks().forEach(track => {
                track.enabled = !isMuted;
            });
        }
    }, [isMuted]);

    // Sync PTT Refs
    useEffect(() => {
        isPttModeRef.current = isPttMode;
        isPttActiveRef.current = isPttActive;
    }, [isPttMode, isPttActive]);

    // Volume Visualizer
    useEffect(() => {
        const updateVolume = () => {
            if (analyserRef.current && isConnected) {
                const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
                analyserRef.current.getByteFrequencyData(dataArray);
                const avg = dataArray.reduce((p, c) => p + c, 0) / dataArray.length;
                setAudioVolume(avg / 255);
            } else {
                setAudioVolume(0);
            }
            animationFrameRef.current = requestAnimationFrame(updateVolume);
        };
        updateVolume();
        return () => {
            if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
        };
    }, [isConnected]);

    // Cleanup on Unmount
    useEffect(() => {
        return () => {
            disconnect();
        };
    }, []);

    // --- Helper Functions (Hoisted) ---

    const stopAudio = () => {
        if (currentSourceRef.current) {
            try {
                currentSourceRef.current.stop();
            } catch (e) { /* ignore */ }
            currentSourceRef.current = null;
        }
        audioQueueRef.current = []; // Clear queue
        isPlayingRef.current = false;
        setIsSpeaking(false);
        if (playbackTimeoutRef.current) {
            clearTimeout(playbackTimeoutRef.current);
            playbackTimeoutRef.current = null;
        }
    };

    const playAudioQueue = async () => {
        if (!audioContextRef.current) return;

        // If we are adding to the queue, ensure we don't erroneously think we stopped.
        if (playbackTimeoutRef.current) {
            clearTimeout(playbackTimeoutRef.current);
            playbackTimeoutRef.current = null;
        }

        // Gate Logic: We are definitely speaking now or will be soon
        isPlayingRef.current = true;
        setIsSpeaking(true);

        if (audioQueueRef.current.length === 0) {
            return;
        }

        while (audioQueueRef.current.length > 0) {
            const nextChunk = audioQueueRef.current.shift();
            if (!nextChunk) continue;

            if (audioContextRef.current.state === 'suspended') {
                console.log("‚ö†Ô∏è AudioContext suspended. Attempting resume...");
                await audioContextRef.current.resume();
                console.log("‚úÖ AudioContext resumed. State:", audioContextRef.current.state);
            }

            try {
                // Determine 24kHz standard for Gemini Live Output
                const sampleRate = 24000;
                const int16Data = new Int16Array(nextChunk);
                const float32Data = new Float32Array(int16Data.length);
                for (let i = 0; i < int16Data.length; i++) {
                    float32Data[i] = int16Data[i] / 32768.0;
                }

                const buffer = audioContextRef.current.createBuffer(1, float32Data.length, sampleRate);
                buffer.getChannelData(0).set(float32Data);

                const source = audioContextRef.current.createBufferSource();
                // Track source to stop it if needed
                currentSourceRef.current = source;
                source.buffer = buffer;
                source.connect(audioContextRef.current.destination);

                // Schedule
                const currentTime = audioContextRef.current.currentTime;
                // Graceful timeline: If fell behind, reset.
                if (nextStartTimeRef.current < currentTime) {
                    console.warn("‚ö†Ô∏è Audio fell behind, resetting timeline. Gap:", (currentTime - nextStartTimeRef.current).toFixed(3));
                    nextStartTimeRef.current = currentTime + 0.05;
                }

                console.log(`üîä Playing Chunk | Duration: ${buffer.duration.toFixed(2)}s | Time: ${nextStartTimeRef.current.toFixed(2)} | Ctx: ${audioContextRef.current.state}`);
                source.start(nextStartTimeRef.current);

                // Advance timer
                const duration = buffer.duration;
                nextStartTimeRef.current += duration;

                source.onended = () => {
                    // DEBOUNCE: Don't set isPlaying=false immediately.
                    // Wait to see if more audio arrives (Network Lag Bridging).
                    if (audioQueueRef.current.length === 0) {
                        if (playbackTimeoutRef.current) clearTimeout(playbackTimeoutRef.current);
                        playbackTimeoutRef.current = setTimeout(() => {
                            if (audioQueueRef.current.length === 0) {
                                setIsSpeaking(false);
                                isPlayingRef.current = false;
                                playbackTimeoutRef.current = null;
                                currentSourceRef.current = null; // FIX: Clear stale ref to allow next playback trigger
                            }
                        }, 600);
                    }
                };

            } catch (err) {
                console.error("Playback Error", err);
            }
        }
    };

    const setupAudioProcessing = async (audioContext: AudioContext, stream: MediaStream, session: any) => {
        try {
            await audioContext.audioWorklet.addModule('/pcm-processor.js');
        } catch (e) { throw new Error("Audio Worklet Load Failed"); }



        if (audioContext.state === 'closed') return;

        const source = audioContext.createMediaStreamSource(stream);
        const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
        (processorRef.current as any) = workletNode;

        const startTime = Date.now();
        const contextSampleRate = audioContext.sampleRate;

        // WATCHDOG REMOVED: conflicting with automatic VAD. 
        // We now rely on Gemini's auto-detection or the manual "Reply Now" button.

        workletNode.port.onmessage = (event) => {
            // 1. Warmup (Increased to 1.5s to settle mic)
            if (Date.now() - startTime < 1500) return;

            // Debug Mic Input (Throttled)
            // if (Math.random() < 0.01) console.log("üé§ Mic Raw Activity (Worklet Running)");

            // 2. Software AEC (Input Gate)
            // DISABLED for Debugging: Allow "Barge In" to prevent stuck mute state.
            // if (isPlayingRef.current) return;

            // PTT Logic
            if (isPttModeRef.current && !isPttActiveRef.current) {
                // If in PTT mode and button NOT held, drop audio.
                return;
            }

            const inputData = event.data;
            let buffer = new Float32Array(inputData);

            // 3. Resampling (Linear Interpolation) if Context != 16k
            if (contextSampleRate !== 16000) {
                const ratio = contextSampleRate / 16000;
                const newLength = Math.floor(buffer.length / ratio);
                const resampled = new Float32Array(newLength);

                for (let i = 0; i < newLength; i++) {
                    const idx = i * ratio;
                    const intIdx = Math.floor(idx);
                    const frac = idx - intIdx;

                    // Linear Interpolation: (1-t)*a + t*b
                    const a = buffer[intIdx] || 0;
                    const b = buffer[intIdx + 1] || a;
                    resampled[i] = a + (b - a) * frac;
                }
                buffer = resampled;
            }

            // DIGITAL GAIN (Pre-amp)
            // Boost input volume by 4x since user mic is very quiet (~0.0002 RMS)
            const inputGain = 4.0;
            for (let i = 0; i < buffer.length; i++) {
                buffer[i] *= inputGain;
            }

            // RMS
            let sum = 0;
            for (let i = 0; i < buffer.length; i++) sum += buffer[i] * buffer[i];
            const rms = Math.sqrt(sum / buffer.length);

            // Skip silence (automatic VAD will handle detection)
            if (rms < 0.0001) return;
            if (isMutedRef.current) return;

            // Convert
            const pcm16 = new Int16Array(buffer.length);
            for (let i = 0; i < buffer.length; i++) {
                let s = Math.max(-1, Math.min(1, buffer[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));

            if (wsSessionRef.current) {
                // Double check connected state to avoid "WebSocket is already in CLOSING or CLOSED state"
                try {
                    // if (Math.random() < 0.01) console.log("üé§ Sending >> RMS:", rms.toFixed(4));
                    // Try sending as 'media' (Blob) as per JSDoc, or 'audio' as per types. Sending both to cover SDK variances.
                    const blob = { mimeType: "audio/pcm;rate=16000", data: base64 };
                    wsSessionRef.current.sendRealtimeInput({ media: blob, audio: blob });
                } catch (e) {
                    // Silent fail if socket closed mid-frame
                    console.debug("Socket send failed", e);
                }
            }
        };

        source.connect(workletNode);
        // Do NOT connect worklet to destination (prevents feedback/echo)
        // workletNode.connect(audioContext.destination);
    };

    const disconnect = (reason?: string) => {
        if (reason) console.log(`Disconnecting: ${reason}`);
        stopAudio();
        if (wsSessionRef.current) {
            wsSessionRef.current = null;
        }
        if (processorRef.current) {
            processorRef.current.disconnect();
            processorRef.current = null;
        }
        if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach(track => track.stop());
            mediaStreamRef.current = null;
        }
        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }
        setIsConnected(false);
        setIsSpeaking(false);
        setStatus("Ready to call");
        setTranscripts([]);
        setCorrection(null);
    };

    const toggleMute = () => {
        setIsMuted(!isMuted);
    };

    const changeRole = (role: any) => {
        setCurrentRole(role);
        if (isConnected) {
            disconnect();
        }
        setTranscripts(prev => [...prev, { role: 'user', text: `(Switched to ${role.label})` }]);
    };

    // Helper for Interactive Text
    const renderInteractiveText = (text: string) => {
        return text.split(' ').map((word, i) => (
            <span
                key={i}
                className="cursor-pointer hover:bg-indigo-500/30 hover:text-white hover:underline decoration-indigo-400 rounded px-0.5 transition-colors"
                onClick={(e) => {
                    e.stopPropagation();
                    // Mock Translation Logic (For visual demo)
                    // In real app: fetch(`/ api / translate ? word = ${ word } `)
                    setSelectedWord({
                        word: word.replace(/[.,!?]/g, ''),
                        translation: "Simulated Translation"
                    });
                }}
            >
                {word}{' '}
            </span>
        ));
    };

    const LANGUAGE_CODES: Record<string, string> = {
        'ES': 'es-US',
        'FR': 'fr-FR',
        'DE': 'de-DE',
        'IT': 'it-IT',
        'EN': 'en-US',
        'PT': 'pt-BR',
        'JP': 'ja-JP',
        'JA': 'ja-JP',
        'CN': 'cmn-CN',
        'ZH': 'cmn-CN',
        'RU': 'ru-RU'
    };
    const targetBCP47 = LANGUAGE_CODES[language] || 'en-US';

    // --- Connect Function ---
    const connect = async () => {
        try {
            setStatus("Requesting Microphone...");
            setError(null);

            // 1. Get Microphone stream FIRST
            // 1. Get raw stream (Disable processing to fix "Quiet Mic")
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: false,
                    autoGainControl: false,
                    noiseSuppression: false
                }
            });
            mediaStreamRef.current = stream;

            // 2. Initialize Audio Context
            const AudioContext = window.AudioContext || (window as any).webkitAudioContext;
            const audioContext = new AudioContext(); // Native sample rate
            audioContextRef.current = audioContext;

            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            // Analyser Setup
            analyserRef.current = audioContext.createAnalyser();
            analyserRef.current.fftSize = 256;

            // 3. Connect to Live API
            setStatus("Connecting to AI...");
            if (!apiKey) throw new Error("API Key missing");
            const genAI = new GoogleGenAI({ apiKey });

            // System Instructions
            const roleInstruction = customSystemInstruction || currentRole.prompt;

            // LOCALIZED HANDSHAKES (The "Hidden" first message)
            const HANDSHAKE_PROMPTS: Record<string, string> = {
                'ES': `[SISTEMA]: Comienza el juego de rol ahora. Habla inmediatamente en Espa√±ol con acento nativo. \nContexto: ${initialMessage}`,
                'FR': `[SYST√àME]: Commencez le jeu de r√¥le maintenant. Parlez imm√©diatement en Fran√ßais avec un accent natif. \nContexte : ${initialMessage}`,
                'DE': `[SYSTEM]: Beginne das Rollenspiel jetzt. Sprich sofort auf Deutsch mit muttersprachlichem Akzent. \nKontext: ${initialMessage}`,
                'IT': `[SISTEMA]: Inizia subito il gioco di ruolo. Parla immediatamente in Italiano con accento nativo. \nContesto: ${initialMessage}`,
                'PT': `[SISTEMA]: Comece o roleplay agora. Fale imediatamente em Portugu√™s com sotaque nativo. \nContexto: ${initialMessage}`,
                'JP': `[SYSTEM]: ‰ªä„Åô„Åê„É≠„Éº„É´„Éó„É¨„Ç§„ÇíÈñãÂßã„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åô„Åê„Å´„Éç„Ç§„ÉÜ„Ç£„Éñ„Å™„Ç¢„ÇØ„Çª„É≥„Éà„ÅßÊó•Êú¨Ë™û„ÇíË©±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ \n„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà: ${initialMessage}`,
                'CN': `[SYSTEM]: Áé∞Âú®ÂºÄÂßãËßíËâ≤ÊâÆÊºî„ÄÇÁ´ãÂç≥‰ª•ÊØçËØ≠Âè£Èü≥ËØ¥‰∏≠Êñá„ÄÇ \nËÉåÊôØ: ${initialMessage}`,
                'RU': `[–°–ò–°–¢–ï–ú–ê]: –ù–∞—á–Ω–∏—Ç–µ —Ä–æ–ª–µ–≤—É—é –∏–≥—Ä—É —Å–µ–π—á–∞—Å. –ì–æ–≤–æ—Ä–∏—Ç–µ —Å—Ä–∞–∑—É –ø–æ-—Ä—É—Å—Å–∫–∏ —Å —Ä–æ–¥–Ω—ã–º –∞–∫—Ü–µ–Ω—Ç–æ–º. \n–ö–æ–Ω—Ç–µ–∫—Å—Ç: ${initialMessage}`,
                'EN': `[SYSTEM]: Start the roleplay now. Speak immediately in English. \nContext: ${initialMessage}`
            };
            // Map aliases
            const handshakeKey = language === 'JA' ? 'JP' : language === 'ZH' ? 'CN' : language;
            const handshake = HANDSHAKE_PROMPTS[handshakeKey] || HANDSHAKE_PROMPTS[language] || HANDSHAKE_PROMPTS['EN'];

            // LOCALIZED SYSTEM PROMPTS ... (Existing map ...)
            const SYSTEM_PROMPTS: Record<string, string> = {
                'ES': `
Eres un tutor de idiomas √∫til y amigable.
Idioma Objetivo: Espa√±ol (${targetBCP47}).
Idioma del Estudiante: ${userNativeLanguageName || 'Ingl√©s'}.

PAUTAS:
1. ROL PRINCIPAL: Act√∫a completamente como el personaje definido.
2. REGLA DE IDIOMA: Habla SOLO en Espa√±ol por defecto.
3. REGLA DE ACENTO: Debes hablar con un acento nativo (Localizaci√≥n: ${targetBCP47}). NO uses acento ingl√©s.
4. EXCEPCI√ìN: Usa ${userNativeLanguageName || 'Ingl√©s'} SOLO si:
   - El usuario est√° claramente confundido.
   - Necesitas explicar un punto gramatical complejo.
   - El usuario pide expl√≠citamente una traducci√≥n.
5. EVITA ESTRICTAMENTE el "Spanglish" o mezclar idiomas.
6. Mant√©n las respuestas concisas (1-3 oraciones).
`,
                'FR': `
Vous √™tes un tuteur de langues utile et amical.
Langue Cible: Fran√ßais (${targetBCP47}).
Langue de l'√âtudiant: ${userNativeLanguageName || 'Anglais'}.

DIRECTIVES:
1. R√îLE PRINCIPAL: Incarnez compl√®tement le personnage d√©fini.
2. R√àGLE DE LANGUE: Parlez UNIQUEMENT en Fran√ßais par d√©faut.
3. R√àGLE D'ACCENT: Vous DEVEZ parler avec un accent natif (Locale: ${targetBCP47}). N'utilisez PAS d'accent anglais.
4. EXCEPTION: Utilisez l'${userNativeLanguageName || 'Anglais'} UNIQUEMENT si:
   - L'utilisateur est clairement confus.
   - Vous devez expliquer un point de grammaire complexe.
   - L'utilisateur demande explicitement une traduction.
5. √âVITEZ STRICTEMENT le "Franglais" ou le m√©lange des langues.
6. Gardez les r√©ponses concises (1-3 phrases).
`,
                'DE': `
Du bist ein hilfreicher und freundlicher Sprachtutor.
Zielsprache: Deutsch (${targetBCP47}).
Sprache des Sch√ºlers: ${userNativeLanguageName || 'Englisch'}.

RICHTLINIEN:
1. HAUPTROLLE: Handele vollst√§ndig als der definierte Charakter.
2. SPRACHREGEL: Sprich standardm√§√üig NUR Deutsch.
3. AKZENTREGEL: Du MUSST mit einem muttersprachlichen Akzent sprechen. Verwende KEINEN englischen Akzent.
4. AUSNAHME: Verwende ${userNativeLanguageName || 'Englisch'} NUR wenn:
   - Der Benutzer offensichtlich verwirrt ist.
   - Du einen komplexen Grammatikpunkt erkl√§ren musst.
   - Der Benutzer ausdr√ºcklich um eine √úbersetzung bittet.
5. Vermeide strikt "Denglisch" oder das Mischen von Sprachen.
6. Halte die Antworten kurz (1-3 S√§tze).
`,
                'IT': `
Sei un tutor di lingue utile e amichevole.
Lingua di destinazione: Italiano (${targetBCP47}).
Lingua dello studente: ${userNativeLanguageName || 'Inglese'}.

LINEE GUIDA:
1. RUOLO PRINCIPALE: Agisci completamente come il personaggio definito.
2. REGOLA DELLA LINGUA: Parla SOLO in Italiano per impostazione predefinita.
3. REGOLA DELL'ACCENTO: DEVI parlare con un accento nativo. NON usare un accento inglese.
4. ECCEZIONE: Usa ${userNativeLanguageName || 'Inglese'} SOLO se:
   - L'utente √® chiaramente confuso.
   - Devi spiegare un punto grammaticale complesso.
   - L'utente chiede esplicitamente una traduzione.
5. EVITARE RIGOROSAMENTE di mescolare le lingue.
6. Mantieni le risposte concise (1-3 frasi).
`,
                'PT': `
Voc√™ √© um tutor de idiomas √∫til e amig√°vel.
Idioma Alvo: Portugu√™s (${targetBCP47}).
Idioma do Estudante: ${userNativeLanguageName || 'Ingl√™s'}.

DIRETRIZES:
1. PAPEL PRINCIPAL: Aja completamente como o personagem definido.
2. REGRA DE IDIOMA: Fale APENAS em Portugu√™s por padr√£o.
3. REGRA DE SOTAQUE: Voc√™ DEVE falar com sotaque nativo. N√ÉO use sotaque ingl√™s.
4. EXCE√á√ÉO: Use ${userNativeLanguageName || 'Ingl√™s'} APENAS se:
   - O usu√°rio estiver claramente confuso.
   - Voc√™ precisar explicar um ponto gramatical complexo.
   - O usu√°rio pedir explicitamente uma tradu√ß√£o.
5. EVITE ESTRITAMENTE misturar idiomas.
6. Mantenha as respostas concisas (1-3 frases).
`,
                'JP': `
„ÅÇ„Å™„Åü„ÅØË¶™Âàá„Åß„Éï„É¨„É≥„Éâ„É™„Éº„Å™Ë™ûÂ≠¶ÊïôÂ∏´„Åß„Åô„ÄÇ
„Çø„Éº„Ç≤„ÉÉ„ÉàË®ÄË™û: Êó•Êú¨Ë™û (${targetBCP47})„ÄÇ
ÁîüÂæí„ÅÆË®ÄË™û: ${userNativeLanguageName || 'Ëã±Ë™û'}„ÄÇ

„Ç¨„Ç§„Éâ„É©„Ç§„É≥:
1. ‰∏ª„Å™ÂΩπÂâ≤: ÂÆöÁæ©„Åï„Çå„Åü„Ç≠„É£„É©„ÇØ„Çø„Éº„Å®„Åó„Å¶ÂÆåÂÖ®„Å´Ë°åÂãï„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
2. Ë®ÄË™û„É´„Éº„É´: „Éá„Éï„Ç©„É´„Éà„Åß„ÅØÊó•Êú¨Ë™û„ÅÆ„Åø„ÇíË©±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
3. „Ç¢„ÇØ„Çª„É≥„Éà„É´„Éº„É´: ÂøÖ„Åö„Éç„Ç§„ÉÜ„Ç£„Éñ„Å™„Ç¢„ÇØ„Çª„É≥„Éà„ÅßË©±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇËã±Ë™û„ÅÆ„Ç¢„ÇØ„Çª„É≥„Éà„ÅØ‰Ωø„Çè„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
4. ‰æãÂ§ñ: ‰ª•‰∏ã„ÅÆÂ†¥Âêà„ÅÆ„Åø ${userNativeLanguageName || 'Ëã±Ë™û'} „Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
   - „É¶„Éº„Ç∂„Éº„ÅåÊòé„Çâ„Åã„Å´Ê∑∑‰π±„Åó„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÇ
   - Ë§áÈõë„Å™ÊñáÊ≥ï‰∫ãÈ†Ö„ÇíË™¨Êòé„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„ÇãÂ†¥Âêà„ÄÇ
   - „É¶„Éº„Ç∂„Éº„ÅåÊòéÁ§∫ÁöÑ„Å´ÁøªË®≥„ÇíÊ±Ç„ÇÅ„ÅüÂ†¥Âêà„ÄÇ
5. Ë®ÄË™û„ÅÆÊ∑∑Âêà„ÇíÂé≥ÂØÜ„Å´ÈÅø„Åë„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
6. ÂõûÁ≠î„ÅØÁ∞°ÊΩî„Å´Ôºà1„Äú3ÊñáÔºâ„ÄÇ
`,
                'CN': `
‰Ω†ÊòØ‰∏Ä‰Ωç‰πê‰∫éÂä©‰∫∫‰∏îÂèãÂ•ΩÁöÑËØ≠Ë®ÄÂØºÂ∏à„ÄÇ
ÁõÆÊ†áËØ≠Ë®Ä: ‰∏≠Êñá (${targetBCP47})„ÄÇ
Â≠¶ÁîüËØ≠Ë®Ä: ${userNativeLanguageName || 'Ëã±ËØ≠'}„ÄÇ

ÂáÜÂàô:
1. ‰∏ªË¶ÅËßíËâ≤: ÂÆåÂÖ®ÊâÆÊºîÂÆö‰πâÁöÑËßíËâ≤„ÄÇ
2. ËØ≠Ë®ÄËßÑÂàô: ÈªòËÆ§Âè™ËØ¥‰∏≠Êñá„ÄÇ
3. Âè£Èü≥ËßÑÂàô: ÂøÖÈ°ª‰ª•ÊØçËØ≠Âè£Èü≥ËØ¥ËØù„ÄÇ‰∏çË¶Å‰ΩøÁî®Ëã±ËØ≠Âè£Èü≥„ÄÇ
4. ‰æãÂ§ñ: ‰ªÖÂú®‰ª•‰∏ãÊÉÖÂÜµ‰∏ã‰ΩøÁî® ${userNativeLanguageName || 'Ëã±ËØ≠'}:
   - Áî®Êà∑ÊòæÁÑ∂Âõ∞ÊÉëÊó∂„ÄÇ
   - ÈúÄË¶ÅËß£ÈáäÂ§çÊùÇÁöÑËØ≠Ê≥ïÁÇπÊó∂„ÄÇ
   - Áî®Êà∑ÊòéÁ°ÆË¶ÅÊ±ÇÁøªËØëÊó∂„ÄÇ
5. ‰∏•Á¶ÅÊ∑∑ÂêàËØ≠Ë®Ä„ÄÇ
6. ‰øùÊåÅÂõûÁ≠îÁÆÄÊ¥ÅÔºà1-3 Âè•ËØùÔºâ„ÄÇ
`,
                'RU': `
–í—ã –ø–æ–ª–µ–∑–Ω—ã–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —è–∑—ã–∫–æ–≤–æ–π —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä.
–¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫: –†—É—Å—Å–∫–∏–π (${targetBCP47}).
–Ø–∑—ã–∫ —É—á–µ–Ω–∏–∫–∞: ${userNativeLanguageName || '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π'}.

–†–£–ö–û–í–û–î–°–¢–í–û:
1. –ì–õ–ê–í–ù–ê–Ø –†–û–õ–¨: –ü–æ–ª–Ω–æ—Å—Ç—å—é –¥–µ–π—Å—Ç–≤—É–π—Ç–µ –∫–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂.
2. –Ø–ó–´–ö–û–í–û–ï –ü–†–ê–í–ò–õ–û: –ì–æ–≤–æ—Ä–∏—Ç–µ –¢–û–õ–¨–ö–û –ø–æ-—Ä—É—Å—Å–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
3. –ü–†–ê–í–ò–õ–û –ê–ö–¶–ï–ù–¢–ê: –í—ã –î–û–õ–ñ–ù–´ –≥–æ–≤–æ—Ä–∏—Ç—å —Å —Ä–æ–¥–Ω—ã–º –∞–∫—Ü–µ–Ω—Ç–æ–º. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∞–∫—Ü–µ–Ω—Ç.
4. –ò–°–ö–õ–Æ–ß–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ${userNativeLanguageName || '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π'} –¢–û–õ–¨–ö–û –µ—Å–ª–∏:
   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —Å–±–∏—Ç —Å —Ç–æ–ª–∫—É.
   - –í–∞–º –Ω—É–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Å–ª–æ–∂–Ω—ã–π –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç.
   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä—è–º–æ –ø—Ä–æ—Å–∏—Ç –ø–µ—Ä–µ–≤–æ–¥.
5. –°–¢–†–û–ì–û –ò–ó–ë–ï–ì–ê–ô–¢–ï —Å–º–µ—à–∏–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤.
6. –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏ (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
`
            };

            // Fallback to English if language not supported in map
            const defaultEnglishPrompt = `
            You are also a helpful bilingual tutor.
            Target Language: ${targetLanguageName || 'Spanish'} (${targetBCP47})
            Learner Language: ${userNativeLanguageName || 'English'}
            
            GUIDELINES:
            1. PRIMARY ROLE: Act the character defined above completely.
            2. LANGUAGE RULE: Speak ONLY in ${targetLanguageName || 'Spanish'} (${targetBCP47}) by default.
            3. ACCENT RULE: You MUST speak with a native ${targetLanguageName || 'Spanish'} accent (Locale: ${targetBCP47}). DO NOT use an English accent.
            4. EXCEPTION: Use ${userNativeLanguageName || 'English'} ONLY if:
               - The user is clearly confused and stuck.
               - You need to explain a complex grammar point.
               - The user explicitly asks for a translation.
            5. STRICTLY AVOID "Franglais" or mixing languages in one sentence unless teaching a specific word mapping.
            6. Keep responses concise (1-3 sentences).
            `;

            const sysKey = language === 'JA' ? 'JP' : language === 'ZH' ? 'CN' : language;
            const tutorInstruction = SYSTEM_PROMPTS[sysKey] || SYSTEM_PROMPTS[language] || defaultEnglishPrompt;
            const systemInstructionText = `${roleInstruction}\n\n${tutorInstruction}`;

            const session = await genAI.live.connect({
                model: MODEL_NAME,
                config: {
                    responseModalities: ["AUDIO"] as any,
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: {
                                voiceName: currentRole.voiceName || 'Aoede'
                            }
                        }
                    },
                    realtimeInputConfig: {
                        automaticActivityDetection: {
                            disabled: false, // Use Gemini's automatic VAD - manual detection wasn't working
                            silenceDurationMs: 1000 // Respond after 1 second of silence
                        }
                    },
                    systemInstruction: {
                        parts: [
                            { text: systemInstructionText }
                        ]
                    }
                },
                callbacks: {
                    onopen: () => {
                        console.log('‚úÖ GEMINI LIVE CONNECTION OPENED');
                        setIsConnected(true);
                        setStatus("Connected (Listening)");
                        setTranscripts([]);
                    },
                    onmessage: (message: any) => {
                        const content = message.serverContent;
                        // console.log("üîç Live Chunk Raw:", JSON.stringify(content, null, 2)); // DEEP LOGGING REMOVED FOR PERFORMANCE

                        if (content?.interrupted) {
                            console.log("AI Interrupted");
                            audioQueueRef.current = [];
                            isPlayingRef.current = false;
                            return;
                        }

                        if (content?.modelTurn) {
                            const turn = content.modelTurn;
                            const text = turn.parts?.find((p: any) => p.text)?.text;
                            if (text) {
                                if (text.includes('```json')) {
                                    try {
                                        const jsonMatch = text.match(/```json\n([\s\S]*?)\n```/);
                                        if (jsonMatch) {
                                            const correctionData = JSON.parse(jsonMatch[1]);
                                            setCorrection(correctionData);
                                            setTimeout(() => setCorrection(null), 10000);
                                            const cleanText = text.replace(jsonMatch[0], '').trim();
                                            if (cleanText) {
                                                const newItem: Transcript = { role: 'model', text: cleanText };
                                                setTranscripts(prev => [...prev, newItem]);
                                                if (onTranscriptUpdate) onTranscriptUpdate(newItem);
                                            }
                                            return;
                                        }
                                    } catch (e) { /* Ignore */ }
                                }
                                if (text.trim()) {
                                    const newItem: Transcript = { role: 'model', text };
                                    setTranscripts(prev => [...prev, newItem]);
                                    if (onTranscriptUpdate) onTranscriptUpdate(newItem);
                                }
                            }

                            const audioPart = turn.parts?.find((p: any) => p.inlineData);
                            if (audioPart?.inlineData?.data) {
                                // console.log("üîä Received Audio Chunk (" + audioPart.inlineData.data.length + " bytes)");
                                const base64 = audioPart.inlineData.data;
                                const binaryString = window.atob(base64);
                                const len = binaryString.length;
                                const bytes = new Uint8Array(len);
                                for (let i = 0; i < len; i++) {
                                    bytes[i] = binaryString.charCodeAt(i);
                                }

                                // BUFFERING STRATEGY:
                                // Gemini sends very small chunks (40ms). Playing them immediately causes gaps/glitching.
                                // We accumulate them into a larger buffer before scheduling.
                                if (!audioBufferRef.current) {
                                    audioBufferRef.current = new Uint8Array(0);
                                }

                                const newBuffer = new Uint8Array(audioBufferRef.current.length + bytes.length);
                                newBuffer.set(audioBufferRef.current);
                                newBuffer.set(bytes, audioBufferRef.current.length);
                                audioBufferRef.current = newBuffer;

                                // Play if we have enough data (e.g., > 24000 bytes ~= 0.5s) or if it's been a while?
                                // Actually, let's just make the chunks bigger. 
                                // 2 bytes per sample. 24000Hz.
                                // 48000 bytes = 1 second.
                                // Let's buffer at least 9600 bytes (200ms) to ensure smooth playback.
                                if (audioBufferRef.current.length >= 9600) {
                                    audioQueueRef.current.push(audioBufferRef.current.buffer as ArrayBuffer);
                                    audioBufferRef.current = new Uint8Array(0);
                                    playAudioQueue();
                                }
                            }
                        }
                    },
                    onclose: (e: any) => {
                        console.warn('üî¥ GEMINI LIVE CONNECTION CLOSED:', e.reason || 'No reason provided');
                        console.warn('Close code:', e.code);
                        setIsConnected(false);
                        setStatus("Disconnected");
                        disconnect();
                    },
                    onerror: (e: any) => {
                        console.error('‚ùå GEMINI LIVE ERROR:', e);
                        console.error('Error details:', JSON.stringify(e, null, 2));
                        setError(e.message || 'Connection error');
                        disconnect();
                    }
                }
            });

            // MOBILE FIX: Resume AudioContext immediately on user gesture (Connect)
            if (audioContextRef.current?.state === 'suspended') {
                await audioContextRef.current.resume();
            }

            wsSessionRef.current = session;

            // 4. Send Initial Prompt
            if (initialMessage) {
                await new Promise(resolve => setTimeout(resolve, 50));

                // CRITCAL FIX: Check if we are still connected after the delay
                if (wsSessionRef.current !== session) {
                    console.warn("Session closed during handshake delay");
                    return;
                }

                try {
                    // PRE-GATE: Do NOT mute mic immediately. Let the user speak if they want.
                    // PRIMING: Send LOCALIZED prompt
                    console.log('üì§ Sending initial handshake:', handshake.substring(0, 100) + '...');
                    await session.sendClientContent({
                        turns: [{ role: 'user', parts: [{ text: handshake }] }],
                        turnComplete: true
                    });
                    console.log('‚úÖ Initial handshake sent successfully');
                } catch (e) {
                    console.error('‚ùå Failed to send initial message:', e);
                }
            }

            // 5. Setup Audio Processing
            await setupAudioProcessing(audioContext, stream, session);

        } catch (err: any) {
            console.error("Connection failed", err);
            setError(err.message || "Failed to connect");
            setStatus("Error");
            disconnect();
        }
    };

    const handleManualReply = () => {
        if (!wsSessionRef.current) return;
        console.log("üëÜ Manual Reply Triggered");
        try {
            (wsSessionRef.current as any).sendRealtimeInput({ activityEnd: {} });
        } catch (e) {
            console.error("Failed to send manual activityEnd", e);
        }
    };

    return (
        <div className="flex flex-col items-center justify-center w-full min-h-[500px] gap-8" onClick={() => setSelectedWord(null)}>
            {/* New: Roleplay Switcher */}
            {!hideRoleSelector && (
                <div className="flex gap-2 mb-4 overflow-x-auto max-w-full pb-2 px-4 hide-scrollbar">
                    {roles.map((role) => {
                        const Icon = role.icon;
                        return (
                            <button
                                key={role.id}
                                onClick={() => changeRole(role)}
                                className={`flex items-center gap-2 px-4 py-2 rounded-full text-sm font-medium transition-colors whitespace-nowrap
                                    ${currentRole.id === role.id
                                        ? 'bg-indigo-600 text-white shadow-lg shadow-indigo-500/30'
                                        : 'bg-gray-800 text-gray-400 hover:bg-gray-700'}`}
                            >
                                <Icon size={16} />
                                {role.label}
                            </button>
                        )
                    })}
                </div>
            )}

            {/* Visualizer & Status & Correction Overlay */}
            <div className="relative w-full max-w-2xl flex flex-col items-center justify-center bg-gray-900/50 rounded-3xl p-8 border border-gray-800 min-h-[400px] overflow-hidden">

                {/* Visualizer Background (Behind Avatar) */}
                <div className="absolute inset-0 z-0 opacity-30 pointer-events-none">
                    <AudioVisualizer
                        analyser={analyserRef.current}
                        isConnected={isConnected}
                        isSpeaking={isSpeaking} // AI Speaking = Purple, Idle/User = Blue/Green
                    />
                </div>

                {/* Avatar / Visualizer Area */}
                <div className="relative flex items-center justify-center w-64 h-64 mb-8 z-10">
                    {/* Pulsing Aura (Keep subtle pulse for avatar specifically) */}
                    <div
                        className={`absolute inset-0 rounded-full blur-3xl transition-all duration-100 ${isSpeaking ? 'bg-indigo-500/30' : 'bg-blue-500/0'}`}
                        style={{
                            transform: `scale(${1 + (audioVolume / 255) * 1.5})`,
                            opacity: 0.3 + (audioVolume / 255)
                        }}
                    />

                    {/* The Avatar Image */}
                    <div
                        className="relative w-48 h-48 rounded-full overflow-hidden border-4 border-gray-800 shadow-2xl transition-transform duration-75"
                        style={{
                            transform: isSpeaking ? `scale(${1 + (audioVolume / 255) * 0.15})` : 'scale(1)',
                            boxShadow: isSpeaking ? `0 0 ${20 + audioVolume / 2}px rgba(99, 102, 241, 0.5)` : 'none' // Glow
                        }}
                    >
                        <img
                            src={`/avatars/${currentRole.id === 'interviewer' ? 'recruiter' : currentRole.id}_${currentRole.id === 'tutor' ? 'friendly' :
                                currentRole.id === 'barista' ? 'cool' :
                                    currentRole.id === 'doctor' ? 'caring' : 'pro'
                                }.png`}
                            alt={currentRole.label}
                            className="w-full h-full object-cover"
                            onError={(e) => { e.currentTarget.style.display = 'none'; }}
                        />
                        {/* Fallback Icon */}
                        <div className="absolute inset-0 flex items-center justify-center bg-gray-800 -z-10">
                            <currentRole.icon size={64} className="text-gray-600" />
                        </div>
                    </div>
                </div>

                {/* Correction Overlay (Toast) */}
                {correction && (
                    <div className="absolute top-4 right-4 animate-fade-in-up sm:static sm:mt-4 z-20">
                        <div className="bg-gray-800/90 backdrop-blur border border-yellow-500/50 p-4 rounded-xl shadow-xl max-w-xs relative overflow-hidden group">
                            <div className="absolute top-0 left-0 w-1 h-full bg-yellow-500"></div>
                            <button onClick={() => setCorrection(null)} className="absolute top-2 right-2 text-gray-500 hover:text-white">&times;</button>
                            <h4 className="text-yellow-400 text-xs font-bold uppercase tracking-wider mb-1 flex items-center gap-2">
                                <Sparkles size={12} /> Live Feedback
                            </h4>
                            <div className="space-y-1">
                                <p className="text-red-400 line-through text-sm">{correction.original}</p>
                                <p className="text-green-400 font-bold text-lg">{correction.correction}</p>
                                <p className="text-gray-400 text-xs italic">{correction.explanation}</p>
                            </div>
                        </div>
                    </div>
                )}

                {/* Status Text (Relative to stay above visualizer) */}
                <div className="text-center z-10 relative">
                    <h3 className={`text-2xl font-bold mb-2 transition-colors ${isConnected ? 'text-white' : 'text-gray-400'}`}>
                        {isConnected ? (isSpeaking ? 'Listening...' : currentRole.label) : "Start Conversation"}
                    </h3>
                    <p className={`text-sm font-medium ${error ? 'text-red-400' : 'text-gray-500'}`}>
                        {error || status}
                    </p>
                </div>

                {/* Transcript / Subtitles (Interactive!) */}
                {/* Transcript / Subtitles REMOVED as per user request */}
                {/* <div className="absolute bottom-4 left-4 right-4 text-center z-20 pointer-events-auto">...</div> */}
                {/* Controls */}
                {/* Controls */}
                {!isConnected ? (
                    <button
                        onClick={connect}
                        className="flex items-center gap-3 px-8 py-4 bg-gradient-to-r from-indigo-600 to-purple-600 hover:from-indigo-500 hover:to-purple-500 text-white rounded-full font-bold text-lg shadow-lg shadow-indigo-500/25 transform transition-all active:scale-95"
                    >
                        <PhoneCall size={24} />
                        Start {currentRole.label} Session
                    </button>
                ) : (
                    <div className="flex flex-col items-center gap-4 animate-fade-in-up">

                        {/* Mode Toggle */}
                        <div className="flex items-center gap-2 bg-white/10 p-1 rounded-full text-xs font-medium">
                            <button
                                onClick={() => setIsPttMode(false)}
                                className={`px-3 py-1 rounded-full transition-colors ${!isPttMode ? 'bg-white text-indigo-600' : 'text-white/60 hover:text-white'}`}
                            >
                                Auto
                            </button>
                            <button
                                onClick={() => setIsPttMode(true)}
                                className={`px-3 py-1 rounded-full transition-colors ${isPttMode ? 'bg-white text-indigo-600' : 'text-white/60 hover:text-white'}`}
                            >
                                Push to Talk
                            </button>
                        </div>

                        <div className="flex items-center gap-6">
                            <button
                                onClick={toggleMute}
                                className={`p-4 rounded-full transition-all duration-300 shadow-lg ${isMuted
                                    ? 'bg-red-500/20 text-red-400 hover:bg-red-500/30 ring-1 ring-red-500/50'
                                    : 'bg-white/10 text-white hover:bg-white/20'
                                    }`}
                            >
                                {isMuted ? <MicOff className="w-6 h-6" /> : <Mic className="w-6 h-6" />}
                            </button>

                            {/* Visualizer / PTT Button */}
                            <div className="relative w-32 h-32 flex items-center justify-center">
                                {/* If PTT Mode: Show Big Button. If Auto: Show Visualizer */}
                                {isPttMode ? (
                                    <button
                                        onMouseDown={() => setIsPttActive(true)}
                                        onMouseUp={() => setIsPttActive(false)}
                                        // Touch events for mobile
                                        onTouchStart={(e) => { e.preventDefault(); setIsPttActive(true); }}
                                        onTouchEnd={(e) => { e.preventDefault(); setIsPttActive(false); }}
                                        className={`w-28 h-28 rounded-full flex items-center justify-center transition-all duration-150 shadow-xl border-4
                                        ${isPttActive
                                                ? 'bg-indigo-500 border-indigo-300 scale-95 ring-4 ring-indigo-500/30'
                                                : 'bg-indigo-600 border-white/20 hover:bg-indigo-500 hover:scale-105'
                                            }
                                    `}
                                    >
                                        <Mic className={`w-10 h-10 text-white ${isPttActive ? 'animate-pulse' : ''}`} />
                                    </button>
                                ) : (
                                    <>
                                        <div className={`absolute inset-0 bg-indigo-500/20 blur-xl rounded-full transition-all duration-75`}
                                            style={{ transform: `scale(${1 + audioVolume * 2})` }}
                                        />
                                        <AudioVisualizer
                                            analyser={analyserRef.current}
                                            isConnected={isConnected}
                                            isSpeaking={isPlayingRef.current}
                                            audioVolume={audioVolume}
                                        />
                                    </>
                                )}
                            </div>

                            <button
                                onClick={handleManualReply}
                                className="p-4 rounded-full bg-blue-500 text-white hover:bg-blue-600 shadow-lg transition-transform hover:scale-105"
                                title="Force Reply"
                            >
                                <MessageSquare className="w-6 h-6" />
                            </button>

                            <button
                                onClick={() => disconnect("User hung up")}
                                className="p-4 rounded-full bg-red-500 text-white hover:bg-red-600 shadow-lg transition-transform hover:scale-105"
                            >
                                <PhoneOff className="w-6 h-6" />
                            </button>
                        </div>
                        {isPttMode && <p className="text-white/50 text-sm animate-pulse">{isPttActive ? "Listening..." : "Hold to speak"}</p>}
                    </div>
                )}

                <p className="text-sm text-gray-500 mt-4">
                    Powered by Gemini 2.5 Multimodal Live
                </p>
            </div>
        </div>
    );
}
